{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all necessary modules\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "#import pymorphy2\n",
    "#import sys\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from numpy import reshape\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "#import math\n",
    "import seaborn as sns\n",
    "#import csv\n",
    "#import os.path\n",
    "#import umap\n",
    "#import hdbscan\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-hearts",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the sequence in which forms are written in the table\n",
    "forms_full = [{'nomn'},{'gent'},{'datv'},{'accs'},{'ablt'},{'loct'},{'gen2'},\n",
    "              {'plur', 'nomn'},{'plur', 'gent'},{'plur', 'datv'},{'plur', 'accs'},{'plur', 'ablt'},{'plur', 'loct'},{'plur', 'gen2'}]\n",
    "tags = ['gender','animacy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here are some functions for getting to the relevant visualizations\n",
    "\n",
    "def base_in_dict(ft, list_forms):\n",
    "    form_in_dict = [[ft.get_word_id(x) for x in line] for line in list_forms]\n",
    "    return form_in_dict\n",
    "\n",
    "def get_all_difference_vectors_as_dict_center_base(list_of_lemmas, vectors_all_nouns, forms_full):\n",
    "    default_dicts = {''.join(case) : [] for case in forms_full}\n",
    "    key2id = {''.join(case) : i for i, case in enumerate(forms_full)}\n",
    "    id2key = [''.join(case) for case in forms_full]\n",
    "    for lemma in range(0, len(list_of_lemmas)):\n",
    "        X = vectors_all_nouns[lemma]\n",
    "        kmeans = KMeans(n_clusters=1, random_state=0).fit(X)\n",
    "        base_vec = kmeans.cluster_centers_[0]\n",
    "        for formid in range(0, 14):\n",
    "            if matrix_of_syncr[lemma][formid] == 2 ** formid:\n",
    "                other_vec = vectors_all_nouns[lemma][formid]\n",
    "                diff = other_vec - base_vec\n",
    "                default_dicts[id2key[formid]].append(diff)\n",
    "    return default_dicts\n",
    "\n",
    "def get_dict_matrix_keys_of_diffs(default_dicts):\n",
    "    keys = []\n",
    "    all_diffs = []\n",
    "    diff_dict = {}\n",
    "    for key, value in default_dicts.items():\n",
    "        if len(value) > 0:\n",
    "            matrix = np.array(value)\n",
    "            mean = np.mean(matrix, 0)\n",
    "            default_dicts[key] = matrix\n",
    "            diff_dict[key] = mean\n",
    "            keys = np.append(keys, np.repeat(key,matrix.shape[0]))\n",
    "            all_diffs = np.append(all_diffs, matrix)\n",
    "    all_diffs_matrix = np.array(all_diffs)\n",
    "    all_diffs_matrix = np.reshape(all_diffs_matrix,(all_diffs_matrix.shape[0]//300,300)) \n",
    "    return diff_dict, all_diffs_matrix, keys\n",
    "\n",
    "def get_dict_matrix_keys_of_diffs_restrict_items(default_dicts, max_number):\n",
    "    keys = []\n",
    "    all_diffs = []\n",
    "    diff_dict = {}\n",
    "    for key, value in default_dicts.items():\n",
    "        if len(value)>0 and len(value)<max_number:\n",
    "            matrix = np.array(value)\n",
    "            mean = np.mean(matrix, 0)\n",
    "            default_dicts[key] = matrix\n",
    "            diff_dict[key] = mean\n",
    "            keys = np.append(keys, np.repeat(key,matrix.shape[0]))\n",
    "            all_diffs = np.append(all_diffs, matrix)\n",
    "        if len(value) >= max_number:\n",
    "            matrix = np.array(value)\n",
    "            random_indices = np.random.choice(matrix.shape[0], size=max_number, replace=False)\n",
    "            random_rows = matrix[random_indices, :]\n",
    "            mean = np.mean(random_rows, 0)\n",
    "            default_dicts[key] = random_rows\n",
    "            diff_dict[key] = mean\n",
    "            keys = np.append(keys, np.repeat(''.join(key),random_rows.shape[0]))\n",
    "            all_diffs = np.append(all_diffs, random_rows)\n",
    "    all_diffs_matrix = np.array(all_diffs)\n",
    "    all_diffs_matrix = np.reshape(all_diffs_matrix,(all_diffs_matrix.shape[0]//300,300)) \n",
    "    return diff_dict, all_diffs_matrix, keys\n",
    "\n",
    "def get_dict_matrix_keys_of_diffs_restrict_syncr(default_dicts, max_number, dim=300):\n",
    "    keys = []\n",
    "    all_diffs = []\n",
    "    diff_dict = {}\n",
    "    for key, value in default_dicts.items():\n",
    "        if len(value) >= max_number:\n",
    "            matrix = np.array(value)\n",
    "            random_indices = np.random.choice(matrix.shape[0], size=max_number, replace=False)\n",
    "            random_rows = matrix[random_indices, :]\n",
    "            mean = np.mean(random_rows, 0)\n",
    "            default_dicts[key] = random_rows\n",
    "            diff_dict[key] = mean\n",
    "            keys = np.append(keys, np.repeat(key,random_rows.shape[0]))\n",
    "            all_diffs = np.append(all_diffs, random_rows)\n",
    "    all_diffs_matrix = np.array(all_diffs)\n",
    "    all_diffs_matrix = np.reshape(all_diffs_matrix,(all_diffs_matrix.shape[0]//dim,dim)) \n",
    "    return diff_dict, all_diffs_matrix, keys\n",
    "\n",
    "\n",
    "def get_all_difference_vectors_as_dict_center_base(list_of_lemmas, vectors_all_nouns, forms_full):\n",
    "    default_dicts = {''.join(case) : [] for case in forms_full}\n",
    "    key2id = {''.join(case) : i for i, case in enumerate(forms_full)}\n",
    "    id2key = [''.join(case) for case in forms_full]\n",
    "    for lemma in range(0, len(list_of_lemmas)):\n",
    "        X = vectors_all_nouns[lemma]\n",
    "        kmeans = KMeans(n_clusters=1, random_state=0).fit(X)\n",
    "        base_vec = kmeans.cluster_centers_[0]\n",
    "        for formid in range(0, 14):\n",
    "            if matrix_of_syncr[lemma][formid] == 2 ** formid:\n",
    "                other_vec = vectors_all_nouns[lemma][formid]\n",
    "                diff = other_vec - base_vec\n",
    "                default_dicts[id2key[formid]].append(diff)\n",
    "    return default_dicts\n",
    "\n",
    "def get_all_difference_vectors_as_dict_center_base_with_min_freq(full_info, list_of_lemmas, vectors_all_nouns, forms_full, min_freq = 100):\n",
    "    default_dicts = {''.join(case) : [] for case in forms_full}\n",
    "    id2key = [''.join(case) for case in forms_full]\n",
    "    for lemma in range(0, len(list_of_lemmas)):\n",
    "        if full_info[lemma][2] != 'None' and float(full_info[lemma][1]) > min_freq:\n",
    "            X = vectors_all_nouns[lemma]\n",
    "            kmeans = KMeans(n_clusters=1, random_state=0).fit(X)\n",
    "            base_vec = kmeans.cluster_centers_[0]\n",
    "            for formid in range(0, 14):\n",
    "                if matrix_of_syncr[lemma][formid] == 2 ** formid:\n",
    "                    other_vec = vectors_all_nouns[lemma][formid]\n",
    "                    diff = other_vec - base_vec\n",
    "                    default_dicts[id2key[formid]].append(diff)\n",
    "    return default_dicts\n",
    "\n",
    "\n",
    "def get_syncretic_difference_vectors_as_dict_center_base_in_dict(matrix_of_syncr, full_info, list_of_lemmas, vectors_all_nouns, forms_full, form_in_dict):\n",
    "    cases = list(set(i for j in matrix_of_syncr for i in j))\n",
    "    default_dicts = {case_id : [] for case_id in cases}\n",
    "    id2key = [''.join(case) for case in forms_full]\n",
    "    for lemma in range(0, len(list_of_lemmas)):\n",
    "        if full_info[lemma][2] != 'None':\n",
    "            X = vectors_all_nouns[lemma]     \n",
    "            X = [X[i] for i in range(0, 14) if (matrix_of_syncr[lemma][i] != 0)]\n",
    "            kmeans = KMeans(n_clusters=1, random_state=0).fit(X)\n",
    "            base_vec = kmeans.cluster_centers_[0]\n",
    "            for formid in range(0, 14):\n",
    "                if matrix_of_syncr[lemma][formid] >= 2 ** formid and form_in_dict[lemma][formid]:\n",
    "                    other_vec = vectors_all_nouns[lemma][formid]\n",
    "                    diff = other_vec - base_vec\n",
    "                    default_dicts[matrix_of_syncr[lemma][formid]].append(diff)\n",
    "    return default_dicts\n",
    "\n",
    "def get_syncretic_difference_vectors_as_dict_center_base_with_min_freq(matrix_of_syncr, full_info, list_of_lemmas, vectors_all_nouns, forms_full, min_freq = 100):\n",
    "    cases = list(set(i for j in matrix_of_syncr for i in j))\n",
    "    default_dicts = {case_id : [] for case_id in cases}\n",
    "    id2key = [''.join(case) for case in forms_full]\n",
    "    for lemma in range(0, len(list_of_lemmas)):\n",
    "        if full_info[lemma][2] != 'None' and float(full_info[lemma][1]) > min_freq:\n",
    "            X = vectors_all_nouns[lemma]     \n",
    "            X = [X[i] for i in range(0, 14) if (matrix_of_syncr[lemma][i] != 0)]\n",
    "            kmeans = KMeans(n_clusters=1, random_state=0).fit(X)\n",
    "            base_vec = kmeans.cluster_centers_[0]\n",
    "            for formid in range(0, 14):\n",
    "                if matrix_of_syncr[lemma][formid] >= 2 ** formid:\n",
    "                    other_vec = vectors_all_nouns[lemma][formid]\n",
    "                    diff = other_vec - base_vec\n",
    "                    default_dicts[matrix_of_syncr[lemma][formid]].append(diff)\n",
    "    return default_dicts\n",
    "\n",
    "def get_dict_matrix_keys_of_diffs_restrict_items(default_dicts, max_number, dim=300):\n",
    "    keys = []\n",
    "    all_diffs = []\n",
    "    diff_dict = {}\n",
    "    for key, value in default_dicts.items():\n",
    "        if len(value) >= max_number:\n",
    "            matrix = np.array(value)\n",
    "            random_indices = np.random.choice(matrix.shape[0], size=max_number, replace=False)\n",
    "            random_rows = matrix[random_indices, :]\n",
    "            mean = np.mean(random_rows, 0)\n",
    "            default_dicts[key] = random_rows\n",
    "            diff_dict[key] = mean\n",
    "            keys = np.append(keys, np.repeat(key,random_rows.shape[0]))\n",
    "            all_diffs = np.append(all_diffs, random_rows)\n",
    "    all_diffs_matrix = np.array(all_diffs)\n",
    "    all_diffs_matrix = np.reshape(all_diffs_matrix,(all_diffs_matrix.shape[0]//dim,dim)) \n",
    "    return diff_dict, all_diffs_matrix, keys\n",
    "\n",
    "def visualize(reduced_vectors, keys, colors, picture_title, filename, columns = 1):\n",
    "    df = pd.DataFrame()\n",
    "    df[\"comp-1\"] = reduced_vectors[:,0]\n",
    "    df[\"comp-2\"] = reduced_vectors[:,1]\n",
    "    df[\"y\"] = keys\n",
    "    g = sns.scatterplot(x=\"comp-1\", y=\"comp-2\", hue=keys,\n",
    "                palette=sns.color_palette(\"hls\", colors),\n",
    "                data=df)\n",
    "    g.set(title=picture_title) \n",
    "    g.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=columns)\n",
    "    plt.savefig(filename, bbox_inches='tight')\n",
    "\n",
    "    \n",
    "pca_50 = PCA(n_components=50)\n",
    "pca_2 = PCA(n_components = 2)\n",
    "tsne = TSNE(n_components=2)\n",
    "tsne3 = TSNE(n_components=3)\n",
    "\n",
    "def run_pca_tsne(vectors):\n",
    "    pca_result_50 = pca_50.fit_transform(vectors)\n",
    "    pca_tsne = tsne.fit_transform(pca_result_50) \n",
    "    return pca_tsne\n",
    "\n",
    "def run_pca(vectors):\n",
    "    pca = pca_2.fit_transform(vectors)\n",
    "    return pca\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the pretrained fasttext model for Russian\n",
    "fasttext.util.download_model('ru', if_exists='ignore')  # Russian\n",
    "ft = fasttext.load_model('cc.ru.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternative: load the model we trained \n",
    "ft = load_ft('/Users/julia/ProductionModels/correlation_analysis/final-model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-architect",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_all_forms = np.loadtxt(\"list_of_noun_forms_full.csv\", dtype=object, delimiter=',')\n",
    "matrix_of_syncr = np.loadtxt(\"matrix_of_syncr.csv\", dtype=float, delimiter=',').astype(int)\n",
    "list_forms = list_of_all_forms[:,4:] #pure forms without lemma, gender, frequency, animacy\n",
    "#in this table a form at index i,j is not syncretic if matrix_of_syncr[i][j]==2**j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the vectors in the array\n",
    "vectors_all_nouns = [[ft.get_word_vector(x) for x in line] for line in list_forms] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-dominant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def_dict = get_all_difference_vectors_as_dict_center_base(list_forms, vectors_all_nouns, forms_full)\n",
    "def_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def_dict['nomn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-japan",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(vectors_all_nouns).to_csv(\"vectors_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "form_in_dict = base_in_dict(ft, list_forms)\n",
    "np.savetxt('form_in_dict.csv', form_in_dict, fmt='%s', delimiter=',')\n",
    "form_in_dict = np.loadtxt(\"form_in_dict.csv\", dtype=float, delimiter=',').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "form_in_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "#100 of the available non-syncretic difference vectors are taken for dimensionality reduction for each case\n",
    "diff_dict, all_diffs_matrix, keys = get_dict_matrix_keys_of_diffs_restrict_items(\n",
    "    get_all_difference_vectors_as_dict_center_base(list_forms, vectors_all_nouns, forms_full),300) \n",
    "pca_tsne = run_pca_tsne(all_diffs_matrix) \n",
    "visualize(pca_tsne, keys, len(diff_dict.keys()), \n",
    "          \"\", \n",
    "          \"pca_tsne_differences_nouns_unique_cases_max_300_base_center.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the available non-syncretic difference vectors of nouns with frequency > 100 are taken for dimensionality reduction\n",
    "diff_dict, all_diffs_matrix, keys = get_dict_matrix_keys_of_diffs(\n",
    "    get_all_difference_vectors_as_dict_center_base_with_min_freq(list_of_all_forms, list_forms, vectors_all_nouns, forms_full, 100))  \n",
    "pca_tsne = run_pca_tsne(all_diffs_matrix) \n",
    "pca = run_pca(all_diffs_matrix)\n",
    "visualize(pca_tsne, keys, len(diff_dict.keys()), \n",
    "          \"\", \n",
    "          \"pca_tsne_differences_nouns_unique_cases_base_center_freq_min_100.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_dict, all_diffs_matrix, keys = get_dict_matrix_keys_of_diffs(\n",
    "    get_syncretic_difference_vectors_as_dict_center_base_with_min_freq(matrix_of_syncr,list_of_all_forms, list_forms, vectors_all_nouns, forms_full))  \n",
    "pca_tsne = run_pca_tsne(all_diffs_matrix) \n",
    "pca = run_pca(all_diffs_matrix)\n",
    "visualize(pca_tsne, keys, len(diff_dict.keys()), \n",
    "          \"\", \n",
    "          \"syncretic_differences_base_center_freq_min_100_our_cbow.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(pca_tsne, keys, len(diff_dict.keys()), \n",
    "          \"\", \n",
    "          \"syncretic_differences_base_center_freq_min_100_our_cbow.png\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-average",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_syncretic_difference_vectors_as_dict_center_base_in_dict\n",
    "diff_dict, all_diffs_matrix, keys = get_dict_matrix_keys_of_diffs_restrict_items(\n",
    "    get_syncretic_difference_vectors_as_dict_center_base_in_dict(matrix_of_syncr,list_of_all_forms, list_forms, vectors_all_nouns, forms_full, form_in_dict),100)  \n",
    "pca_tsne = run_pca_tsne(all_diffs_matrix) \n",
    "pca = run_pca(all_diffs_matrix)\n",
    "visualize(pca_tsne, keys, len(diff_dict.keys()), \n",
    "          \"\", \n",
    "          \"syncretic_differences_base_center_freq_in_dict_our_cbow_max_100.png\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-plumbing",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_syncretic_difference_vectors_as_dict_center_base_in_dict\n",
    "diff_dict, all_diffs_matrix, keys = get_dict_matrix_keys_of_diffs(\n",
    "    get_syncretic_difference_vectors_as_dict_center_base_in_dict(matrix_of_syncr,list_of_all_forms, list_forms, vectors_all_nouns, forms_full, form_in_dict))  \n",
    "pca_tsne = run_pca_tsne(all_diffs_matrix) \n",
    "pca = run_pca(all_diffs_matrix)\n",
    "visualize(pca_tsne, keys, len(diff_dict.keys()), \n",
    "          \"\", \n",
    "          \"syncretic_differences_base_center_freq_in_dict_our_cbow.png\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_with_categories = np.loadtxt(\"noun_categories.csv\", dtype=object, delimiter=';')\n",
    "nouns_with_categories = np.delete(nouns_with_categories,[4],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-shareware",
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_categories = nouns_with_categories[:,1:-1]\n",
    "condition = (noun_categories[-1, :].astype(float)>=20)\n",
    "big_categories = noun_categories[:, condition]\n",
    "big_category_names = nouns_with_categories [:, 1:-1]\n",
    "big_category_names = big_category_names[0,condition]\n",
    "filter_nouns = np.sum(big_categories[1:-1, :].astype(float), axis = 1) >= 1\n",
    "selected_noun_stems = nouns_with_categories[1:-1]\n",
    "selected_noun_stems = selected_noun_stems[filter_nouns,0]\n",
    "big_categories = big_categories[1:-1]\n",
    "big_categories = big_categories[filter_nouns,:]\n",
    "categories = []\n",
    "category_labels = []\n",
    "for i in range(0,len(selected_noun_stems)):\n",
    "    cat_condition = (big_categories[i,:].astype(float) == 1)\n",
    "    cat = big_category_names[cat_condition]\n",
    "    categories = np.append(categories, cat[0])\n",
    "    category_labels = np.append(category_labels, ' '.join(cat))\n",
    "vectors_nouns_with_categories = [ft.get_word_vector(x) for x in selected_noun_stems] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-therapy",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_tsne = run_pca_tsne(vectors_nouns_with_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"comp-1\"] = pca_tsne[:,0]\n",
    "df[\"comp-2\"] = pca_tsne[:,1]\n",
    "df[\"y\"] = categories\n",
    "df[\"word\"] = selected_noun_stems\n",
    "df[\"label\"] = category_labels\n",
    "fig = px.scatter(df, x=\"comp-1\", y=\"comp-2\", custom_data=[\"word\", \"label\"],\n",
    "              color=df.y.tolist())\n",
    "fig.update_traces(\n",
    "    hovertemplate=\"<br>\".join([\n",
    "        \"ColX: %{customdata[0]}\",\n",
    "        \"Col1: %{customdata[1]}\"\n",
    "    ])\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image('/Users/julia/ProductionModels/images/noun_categories.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
