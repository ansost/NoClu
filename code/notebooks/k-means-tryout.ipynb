{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letzter Stand\n",
    "- Meeting mit Informatikperson: 7. September 11:00\n",
    "- Fact-checked output of preprocessing script. \n",
    "- re-shaping does not have to be done for non-synchr. input vectors.\n",
    "\n",
    "Todo:\n",
    "- Hab ich die Reihenfolge von dimensionality reduction & clustering richtig verstanden?\n",
    "  - Folien von Yulias Vortrag & Anastasia durchgehen\n",
    "  - https://tacosconference.github.io/css/2023_style/TalkSlides/YABLOKOVA.pdf\n",
    "- Je nach above, dimensions von clustering output für PCA anpassen oder andersrum durchführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score\n",
    "import fasttext as ft\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- die scikit learn documentation empfiehlt PCA vor k means laufen zu lassen und wird machen das Gegenteil??\n",
    "- k means sucht nach cluster with equal variance, ist das bei unseren clulstern gegeben?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data.\n",
    "forms_full = [\n",
    "    {\"nomn\"},\n",
    "    {\"gent\"},\n",
    "    {\"datv\"},\n",
    "    {\"accs\"},\n",
    "    {\"ablt\"},\n",
    "    {\"loct\"},\n",
    "    {\"gen2\"},\n",
    "    {\"plur\", \"nomn\"},\n",
    "    {\"plur\", \"gent\"},\n",
    "    {\"plur\", \"datv\"},\n",
    "    {\"plur\", \"accs\"},\n",
    "    {\"plur\", \"ablt\"},\n",
    "    {\"plur\", \"loct\"},\n",
    "    {\"plur\", \"gen2\"},\n",
    "]\n",
    "\n",
    "# For each noun: Lemma, tags (gender, animacy), something, all 14 cases (see above).\n",
    "list_of_all_forms = np.loadtxt(\n",
    "    \"../../data/list_of_noun_forms_full.csv\", dtype=object, delimiter=\",\"\n",
    ")\n",
    "\n",
    "# Binary coding of synchretisms. A form at index i,j is not syncretic if matrix_of_syncr[i][j]==2**j.\n",
    "matrix_of_syncr = np.loadtxt(\n",
    "    \"../../data/matrix_of_syncr.csv\", dtype=float, delimiter=\",\"\n",
    ").astype(int)\n",
    "\n",
    "# List of cases without lemma and tags.\n",
    "list_forms = list_of_all_forms[:, 4:]\n",
    "\n",
    "# Load fasttext model.\n",
    "model = ft.load_model(\".l./../data/final-model.bin\")\n",
    "\n",
    "# Get all the vectors in the array.\n",
    "# Gets the vector for all word lemmas from list_forms.\n",
    "vectors_all_nouns = [[model.get_word_vector(x) for x in line] for line in list_forms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.load(\"../../data/nonsynchr_casevectors.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing synchronous forms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`list_forms` and `matrix of synchr.` have the same length so presumably the same structure.\n",
    "> 11515 lines and 14 dims per line \n",
    "\n",
    "```python\n",
    "matrix_of_syncr[0]\n",
    "array([   1,   74,    4,   74,   16,   32,   74,  128, 9472,  512, 9472,\n",
    "       2048, 4096, 9472])\n",
    "```\n",
    "\n",
    "```python\n",
    "list_forms[0]\n",
    "array(['человек', 'человека', 'человеку', 'человека', 'человеком',\n",
    "       'человеке', 'человека', 'люди', 'людей', 'людям', 'людей',\n",
    "       'людьми', 'людях', 'людей'], dtype=object)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get case vectors for all non-synchretic cases.\n",
    "nonsynchr_casevectors = []\n",
    "for form in range(0, len(list_forms)):\n",
    "    for case in range(0, 14):\n",
    "        if (\n",
    "            matrix_of_syncr[form][case] == 2**case\n",
    "        ):  # Get word vector if case is not synchretic.\n",
    "            vector = model.get_word_vector(list_forms[form][case])\n",
    "            nonsynchr_casevectors.append(vector)\n",
    "print(len(nonsynchr_casevectors), len(list_forms))  # 68687 11515\n",
    "# np.save('../data/nonsynchr_casevectors.npy', nonsynchr_casevectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.load(\"../../data/nonsynchr_casevectors.npy\")\n",
    "d.shape  # (68687, 300)\n",
    "# model.get_word_vector(\"человек\").shape # (300,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectors_all_nouns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_kmeans(n_clusters, input):\n",
    "    \"\"\"Cluster the input into n_clusters using kmeans.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_clusters: int\n",
    "        Number of clusters to cluster the input into.\n",
    "    input: array-like\n",
    "        Input to cluster.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    labels: array-like\n",
    "        Cluster labels for each element in the input.\n",
    "    centers: array-like\n",
    "        Cluster centers.\n",
    "    \"\"\"\n",
    "    x = np.ascontiguousarray(input)\n",
    "    # nsamples, nx, ny = x.shape\n",
    "    # x = x.reshape((nsamples, nx * ny))\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=\"auto\").fit(x)\n",
    "    return kmeans.labels_, kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = cluster_kmeans(8, d)  # Whats a good number of clusters?\n",
    "# d = np.load(\"../../data/nonsynchr_casevectors.npy\")\n",
    "kmeans = KMeans(n_clusters=9, random_state=0, n_init=\"auto\").fit(d)\n",
    "# explain the random state parameter in kmeans\n",
    "kmeans_silhouette = silhouette_score(d, kmeans.labels_).round(2)\n",
    "kmeans_silhouette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dim reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The PCA/TSNE n_dimensions that anastasia used:\n",
    "# pca: 2/50 dimensions\n",
    "# tsne: 2/3 dimensions\n",
    "\n",
    "\n",
    "def run_pca(vectors, pca_dims):\n",
    "    \"\"\"Run dimensionality reduction using Principal Component Analysis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vectors: array-like\n",
    "        Vectors to reduce.\n",
    "    pca_dims: int\n",
    "        Number of dimensions to reduce to.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results: array-like\n",
    "        Reduced vectors.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=pca_dims)\n",
    "    results = pca.fit_transform(vectors)\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_pca_tsne(vectors, pca_dims, tsne_dims):\n",
    "    \"\"\"Run dimensionality reduction using Principal Component Analysis and t-SNE in that order.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vectors: array-like\n",
    "        Vectors to reduce.\n",
    "    pca_dims: int\n",
    "        Number of dimensions to reduce to using PCA.\n",
    "    tsne_dims: int\n",
    "        Number of dimensions to reduce to using t-SNE.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tsne_result: array-like\n",
    "        Reduced vectors.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=pca_dims)\n",
    "    tsne = TSNE(n_components=tsne_dims)\n",
    "    pca_result = pca.fit_transform(vectors)\n",
    "    tsne_result = tsne.fit_transform(pca_result)\n",
    "    return tsne_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = run_pca(, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nocluV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
